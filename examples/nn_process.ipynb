{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, json\n",
    "from argparse import Namespace\n",
    "from flat_reach_RL import *\n",
    "from nnet_util import torch_model_to_nnet, onnx_to_nnet\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = \"/Users/changliuliu/Documents/GitHub/Composable_Agent_Toolbox/examples/output/FlatReach_near_C200_H32_Nm100.0_lr0.001\"\n",
    "# demo_path = \"/home/ruic/Documents/RESEARCH/ICL/Composable_Agent_Toolbox/examples/output/FlatReach_near_C200_H32_Nm100.0_lr0.001\"\n",
    "demo_ep = 300\n",
    "\n",
    "with open(os.path.join(demo_path, \"args.json\"), \"r\") as infile:\n",
    "    config = json.load(infile)\n",
    "args_saved = Namespace(**config)\n",
    "\n",
    "args_saved.demo = True\n",
    "args_saved.demo_path = demo_path\n",
    "args_saved.demo_ep = demo_ep\n",
    "\n",
    "args = args_saved\n",
    "\n",
    "STATE_DIMENSION = 8\n",
    "ACTION_SPACE_SIZE = 17\n",
    "\n",
    "device = 'cpu'\n",
    "# device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_tensor(s, device):\n",
    "    '''\n",
    "        [1, dS]\n",
    "    '''\n",
    "    return torch.from_numpy(np.asarray(s)).unsqueeze(0).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = QNetwork(env_name=args.env_name,\n",
    "            state_dim=STATE_DIMENSION,\n",
    "            num_of_actions=ACTION_SPACE_SIZE,\n",
    "            hidden_size=args.hidden_size).to(device)\n",
    "\n",
    "checkpt_path = os.path.join(args.demo_path, 'checkpts', '{}_{}.pt'.format(args.env_name, args.demo_ep))\n",
    "Q.load_model_weights(checkpt_path)\n",
    "Q.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANGLE_DISCRETE_SIZE = 8\n",
    "ACC_MIN = 50\n",
    "ACC_MAX = 100\n",
    "ACC_DISCRETE_SIZE = 2\n",
    "ACTION_SPACE_SIZE = 1 + ANGLE_DISCRETE_SIZE * ACC_DISCRETE_SIZE\n",
    "\n",
    "def get_action(Q, state, device):\n",
    "\n",
    "    action_id = Q(state_to_tensor(state, device)).argmax().item()\n",
    "\n",
    "    if action_id == 0:\n",
    "        action = [0, 0]\n",
    "    else:\n",
    "        action_id_non_zero = action_id - 1\n",
    "        angle = 2*np.pi / ANGLE_DISCRETE_SIZE * (action_id_non_zero % ANGLE_DISCRETE_SIZE)\n",
    "        mag = np.floor(action_id_non_zero/ANGLE_DISCRETE_SIZE)*(ACC_MAX-ACC_MIN)/(ACC_DISCRETE_SIZE-1) + ACC_MIN\n",
    "        action = [mag*np.cos(angle), mag*np.sin(angle)]\n",
    "    \n",
    "    return action_id, np.asarray(action).reshape(-1)\n",
    "\n",
    "# numerical examples\n",
    "# state = [goal_rel_pos, goal_rel_vel, obs_rel_pos, obs_rel_vel]\n",
    "\n",
    "# When obstacle is far, changing goal distance should not change action\n",
    "state = [10, 0, -1, 0, 0, 50, 0, 0]\n",
    "print(get_action(Q, state, device))\n",
    "\n",
    "state = [5, 0, -1, 0, 0, 50, 0, 0]\n",
    "print(get_action(Q, state, device))\n",
    "\n",
    "# When obstacle is not on the way to goal, changing obstacle vel should not change action\n",
    "state = [10, 0, -1, 0, 0, 50, 0, 0]\n",
    "print(get_action(Q, state, device))\n",
    "\n",
    "state = [10, 0, -1, 0, 0, 50, 0, -1]\n",
    "print(get_action(Q, state, device))\n",
    "\n",
    "# When obstacle is on the way to goal, changing goal distance should not change action\n",
    "state = [20, 0, -1, 0, 10, 0, -2, 0]\n",
    "print(get_action(Q, state, device))\n",
    "\n",
    "state = [25, 0, -1, 0, 10, 0, -2, 0]\n",
    "print(get_action(Q, state, device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# test obstacle position where goal pos change will change action\n",
    "\n",
    "obs_pos = [6, 0]  # distance <= 6,          goal changes action\n",
    "obs_pos = [13, 0] # distance in [7, 13],    goal doesn't change action\n",
    "obs_pos = [20, 0] # distance in [14, 30],   goal changes action\n",
    "goal_pos_1 = [20, 10]\n",
    "goal_pos_2 = [20, 20]\n",
    "\n",
    "state = goal_pos_1 + [-1, 0] + obs_pos + [-1, 0]\n",
    "print(get_action(Q, state, device))\n",
    "\n",
    "state = goal_pos_2 + [-1, 0] + obs_pos + [-1, 0]\n",
    "print(get_action(Q, state, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, STATE_DIMENSION).to(device)\n",
    "input_names = [\"dummy_input\"]\n",
    "output_names = [\"output\"]\n",
    "\n",
    "torch.onnx.export(Q, \n",
    "                  dummy_input,\n",
    "                  f\"{demo_ep}.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names,\n",
    "                  export_params=True,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model_to_nnet(Q, f\"{demo_ep}.nnet\", decimal=8) # saving 8 digits. More can be used, but that requires more more space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_to_nnet(f\"{demo_ep}.onnx\", f\"{demo_ep}.nnet\", decimal=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_inference(file, input):\n",
    "    sess = onnxruntime.InferenceSession(\n",
    "        file, providers=onnxruntime.get_available_providers())\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    pred_onx = sess.run(None, {input_name: input.astype(np.float32)})[0]\n",
    "    print(pred_onx)\n",
    "\n",
    "input = np.array([[1,2,3,4,5,6,7,8]])\n",
    "onnx_inference(\"300.onnx\", input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test nnet in julia using the following code:\n",
    "# the output could be slightly different due to digits used for saving nnet\n",
    "\n",
    "using NeuralVerification\n",
    "net = read_nnet(\"300.nnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1: when the obstacle is far, changing goal distance should not change action\n",
    "input = [10.0, 0.0, -1.0, 0.0, 0.0, 50.0, 0.0, 0.0]\n",
    "\n",
    "# Check the desired action\n",
    "output = NeuralVerification.compute_output(net, input)\n",
    "desired_action = argmax(output) # Note Julia's index starts from 1\n",
    "\n",
    "# Now check whether the input can tolerate some perturbation\n",
    "radius = [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] # This parameter is tunable\n",
    "input_set  = NeuralVerification.Hyperrectangle(input, radius)\n",
    "\n",
    "# Choose solver\n",
    "solver = MIPVerify()\n",
    "\n",
    "# Problem 1. Now we check if the desired_action remains the same for all inputs in the input_set\n",
    "for i in 1:17\n",
    "    if i != desired_action\n",
    "        vec = zeros(1,17)\n",
    "        vec[i] = 1.0\n",
    "        vec[desired_action] = -1.0\n",
    "        output_set = NeuralVerification.HPolytope(vec, [0.0])\n",
    "        problem = Problem(net, input_set, output_set)\n",
    "        result = solve(solver, problem)\n",
    "        println(\"action pair: \",i, \",\", desired_action, \": \",result.status)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Problem 2. Now let us check at which distance the obstacle can affect the action (make the adjacent action optimal)\n",
    "index = 6\n",
    "dmin = 0.0\n",
    "dmax = 50.0\n",
    "while dmax>dmin+0.1\n",
    "    input[index] = (dmax+dmin)/2.0\n",
    "    input_set  = NeuralVerification.Hyperrectangle(input, radius)\n",
    "    output = NeuralVerification.compute_output(net, input)\n",
    "    desired_action = argmax(output) # Note Julia's index starts from 1\n",
    "    for i in 1:17\n",
    "        if i != desired_action\n",
    "        vec = zeros(1,17)\n",
    "        vec[i] = 1.0\n",
    "        vec[desired_action] = -1.0\n",
    "        output_set = NeuralVerification.HPolytope(vec, [0.0])\n",
    "        problem = Problem(net, input_set, output_set)\n",
    "        model = NeuralVerification.Model(solver)\n",
    "        z = NeuralVerification.init_vars(model, problem.network, :z, with_input=true)\n",
    "        δ = NeuralVerification.init_vars(model, problem.network, :δ, binary=true)\n",
    "        # get the pre-activation bounds:\n",
    "        model[:bounds] = NeuralVerification.get_bounds(problem, before_act=true)\n",
    "        model[:before_act] = true\n",
    "        NeuralVerification.add_set_constraint!(model, problem.input, first(z))\n",
    "        NeuralVerification.add_complementary_set_constraint!(model, problem.output, last(z))\n",
    "        NeuralVerification.encode_network!(model, problem.network, NeuralVerification.BoundedMixedIntegerLP())\n",
    "        o = NeuralVerification.max_disturbance!(model, first(z) - problem.input.center)\n",
    "        NeuralVerification.optimize!(model)\n",
    "        if NeuralVerification.termination_status(model) == NeuralVerification.OPTIMAL\n",
    "            println(\"Counter example:\",NeuralVerification.value(first(z)))\n",
    "            dmin = input[index]\n",
    "            break\n",
    "        end\n",
    "        end\n",
    "    end\n",
    "    if dmin != input[index]\n",
    "        dmax = input[index]\n",
    "    end\n",
    "    println(\"[\",dmin,\",\",dmax,\"]\")\n",
    "end\n",
    "\n",
    "# Problem 3. Choose different solvers\n",
    "input = [10.0, 0.0, -1.0, 0.0, 0.0, 50.0, 0.0, 0.0]\n",
    "radius = [10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] # This parameter is tunable\n",
    "input_set  = NeuralVerification.Hyperrectangle(input, radius)\n",
    "solver = ReluVal(max_iter = 50) # max_iter is a tunable parameter. there will be fewer unknowns if we set max_iter to be big enough\n",
    "for i in 1:17\n",
    "    if i != desired_action\n",
    "        vec = zeros(1,17)\n",
    "        vec[i] = 1.0\n",
    "        vec[desired_action] = -1.0\n",
    "        output_set = NeuralVerification.HPolytope(vec, [0.0])\n",
    "        problem = Problem(net, input_set, output_set)\n",
    "        result = solve(solver, problem)\n",
    "        println(\"action pair: \",i, \",\", desired_action, \": \",result)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2: When obstacle is not on the way to goal, changing obstacle vel should not change action\n",
    "input = [10, 0, -1, 0, 0, 50, 0, 0]\n",
    "\n",
    "# Check the desired action\n",
    "output = NeuralVerification.compute_output(net, input)\n",
    "desired_action = argmax(output) # Note Julia's index starts from 1\n",
    "\n",
    "# Now check whether the input can tolerate some perturbation\n",
    "radius = [0, 0, 0, 0, 0, 0, 0, 10] # This parameter is tunable\n",
    "input_set  = NeuralVerification.Hyperrectangle(input, radius)\n",
    "\n",
    "# Choose solver\n",
    "solver = MIPVerify()\n",
    "\n",
    "# Now we check if the desired_action remains the same for all inputs in the input_set\n",
    "for i in 1:17\n",
    "    if i != desired_action\n",
    "        vec = zeros(1,17)\n",
    "        vec[i] = 1.0\n",
    "        vec[desired_action] = -1.0\n",
    "        output_set = NeuralVerification.HPolytope(vec, [0.0])\n",
    "        problem = Problem(net, input_set, output_set)\n",
    "        result = solve(solver, problem)\n",
    "        println(result)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 3: When obstacle is on the way to goal, changing goal distance should not change action\n",
    "input = [20, 0, -1, 0, 10, 0, -2, 0]\n",
    "\n",
    "# Check the desired action\n",
    "output = NeuralVerification.compute_output(net, input)\n",
    "desired_action = argmax(output) # Note Julia's index starts from 1\n",
    "\n",
    "# Now check whether the input can tolerate some perturbation\n",
    "radius = [10, 0, 0, 0, 0, 0, 0, 0] # This parameter is tunable\n",
    "input_set  = NeuralVerification.Hyperrectangle(input, radius)\n",
    "\n",
    "# Choose solver\n",
    "solver = MIPVerify()\n",
    "\n",
    "# Now we check if the desired_action remains the same for all inputs in the input_set\n",
    "for i in 1:17\n",
    "    if i != desired_action\n",
    "        vec = zeros(1,17)\n",
    "        vec[i] = 1.0\n",
    "        vec[desired_action] = -1.0\n",
    "        output_set = NeuralVerification.HPolytope(vec, [0.0])\n",
    "        problem = Problem(net, input_set, output_set)\n",
    "        result = solve(solver, problem)\n",
    "        println(result)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM 1: CHECK IF THE POLICY IS ROBUST UNDER INPUT PERTURBATION ** CHECK EVERY ACTION PAIR\n",
    "\n",
    "# PROBLEM 2: COMPUTE THE MAXIMUM RANGE OF PERTURBATION\n",
    "\n",
    "# PROBLEM 3: COMPARE THE PERFORMANCE OF DIFFERENT SOLVERS: computation time, conservativeness\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "6030eb738c8acb4f83a1f3daa211682723451309cff055d0309698eea07fbfaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
