{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "from os.path import abspath, join, dirname\n",
    "sys.path.append(\"../\") # Adds higher directories to python modules path\n",
    "import numpy as np\n",
    "import evaluator, agent, env\n",
    "import time\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, we will define a 2D reaching task and evaluate two model based agents. The two agents represent the robot and the human separately. \n",
    "\n",
    "We first define the testing environment with `env_spec`, and then define the computational models (model based agents) that give the control signals with `agents`.\n",
    "\n",
    "In the end, we instantiate this environment with the `env_spec` and `agents`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Environment\n",
    "\n",
    "The environment is fully characterized by `env_spec`. `env_spec` contains `world`, `dt` and `agent_env_spec`.\n",
    "\n",
    "`world` specifies which physics engine we use, here we use a 2D physics engine.\n",
    "\n",
    "`dt` is the time sampling separation.\n",
    "\n",
    "`agent_env_spec` specifies the physical agents (car, robot arm, ball, etc) that will be controlled by the computational model.\n",
    "\n",
    "### Physical Agent\n",
    "\n",
    "We will use two BB8 agents, which are essentially balls. \n",
    "\n",
    "`agent_env_spec`: A dictionary, the key is the name of the physical agent, and the value is the specification. \n",
    "\n",
    "`type`: The type of the physical agent, see \"env/flat_world/agent.py\" for all available agents. \n",
    "\n",
    "`spec` The parameters required by the physical agent for initialization. For the `BB8Agent`, we only need to provide the init state, which is `[x, y, vx, vy]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_env_spec = {\"robot\":{\"type\":\"BB8Agent\", \"spec\":{\"init_x\":np.vstack([ 30.,20.0, 0., 0.])}},\n",
    "                  \"human\":{\"type\":\"BB8Agent\", \"spec\":{\"init_x\":np.vstack([ 50.,20.0, 0., 0.])}}\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### World\n",
    "\n",
    "We use a 2D physics engine, which we call `FlatReachingWorld`. This engine requires some parameters which we specified in `reaching_world_spec`.\n",
    "\n",
    "`friction`: Friction force.\n",
    "\n",
    "`reaching_eps`: $L_\\infty$ tolerance to decide whether the agent reaches the goal.\n",
    "\n",
    "`agent_goal_lists`: Goals for each agent, once the agent reaches a goal, this goal will disapper and the next goal will show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaching_world_spec = {\n",
    "    \"friction\": 0,\n",
    "    \"reaching_eps\": 0.1,\n",
    "    \"agent_goal_lists\":{\n",
    "        \"robot\": [[70.0,20.0], [10, 40]],\n",
    "        \"human\": [[10.0,20.0], [40, 70]],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the `env_spec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.02\n",
    "env_spec = {\n",
    "    \"world\": {\"type\":\"FlatReachingWorld\", \"spec\":reaching_world_spec},\n",
    "    \"dt\": dt,\n",
    "    \"agent_env_spec\": agent_env_spec\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next, we define the computational model for each physical agent. We use model-based agents as computational models.\n",
    "\n",
    "## Model-based Agent\n",
    "\n",
    "We define a model based agent by specifying the `task`, `estimator`, `planner`, `controller` and `sensors`. The specification of each module is composed by two parts, `type` and `spec`.\n",
    "\n",
    "### Task\n",
    "\n",
    "The task module tells the agent what to do by giving the agent a reference goal computed from the observations. Here we define a FlatReachingTask. This task asks the agent to reach a point in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_spec = {\"type\":\"FlatReachingTask\",    \"spec\":{}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "The model module contains structured differentiable functions that either represent system dynamics or control policies. This module will be used by estimator, planner and controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = {\"type\":\"LinearModel\",     \"spec\":{\"use_spec\":0, \n",
    "                                                \"use_library\":0, \n",
    "                                                \"model_name\":'Ballbot', \n",
    "                                                \"time_sample\":dt, \n",
    "                                                \"disc_flag\":1, \n",
    "                                                \"model_spec\":None,\n",
    "                                                \"control_input_dim\":2}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "\n",
    "The estimator module contains a class of functions that filt raw observations and estimate agent state. Here we define a UKF estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_spec = {\"type\":\"EKFEstimator\",   \"spec\":{\"init_x\":np.array([ 30.,20.0, 0., 0.]),\n",
    "                                                   \"init_variance\":.01*np.eye(4),\n",
    "                                                   \"Rww\":.001*np.eye(4),\n",
    "                                                   \"Rvv\":.001*np.eye(4),\n",
    "                                                   \"alpha_ukf\":1,\n",
    "                                                   \"kappa_ukf\":0.1,\n",
    "                                                   \"beta_ukf\":2,\n",
    "                                                   \"time_sample\":dt,\n",
    "                                                   \"kp\":6,\n",
    "                                                   \"kv\":8}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planner\n",
    "The  planner  module  contains  a  class  of  functions  that  map  observation  to  asequence  of  future  states  of  future  inputs. Here we define a optimization based planner. This planner will plan a trajectory based on current location and the goal provided by the task module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_spec = {\"type\":\"OptimizationBasedPlanner\",\"spec\":{\"horizon\":10, \n",
    "                                                          \"replanning_cycle\":10, \n",
    "                                                          \"dim\":2, \n",
    "                                                          \"n_ob\":1, \n",
    "                                                          \"obs_r\":5}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controller\n",
    "\n",
    "The controller module contains a class of functions that map observation to thenext control input. Here we define a PID controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_spec = {\"type\":\"NaiveController\", \"spec\":{\"kp\":6,\n",
    "                                                     \"kv\":8}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor\n",
    "\n",
    "The sensor module defines the sensors the agent equiped. An agent can have multiple sensors. Each sensor has an alias. The alias tells us what this sensor is used for. Because there are multiple sensors can do the same work. For short, `alias` describe the purpose of the sensor, and `type` describe the function.\n",
    "\n",
    "Check the \"env/XXX_worlds/sensors\" to see avaiable sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_spec = [{\"type\":\"PVSensor\",                \"spec\":{\"alias\":\"cartesian_sensor\",\"noise_var\":0.1}},\n",
    "                {\"type\":\"StateSensor\",             \"spec\":{\"alias\":\"state_sensor\",    \"noise_var\":0.1}},\n",
    "                {\"type\":\"RadarSensor\",             \"spec\":{\"alias\":\"obstacle_sensor\", \"noise_var\":0.1}},\n",
    "                {\"type\":\"GoalSensor\",              \"spec\":{\"alias\":\"goal_sensor\",     \"noise_var\":0.0}},\n",
    "                {\"type\":\"RadioSensor\",             \"spec\":{\"alias\":\"communication_sensor\"}},\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Agent\n",
    "\n",
    "Now we assemble the agent by combining all these modules. And give the agent a name as \"robot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1_module_spec = {\n",
    "        \"name\":      \"robot\",\n",
    "        \"task\":      task_spec,\n",
    "        \"model\":     model_spec,\n",
    "        \"estimator\": estimator_spec,\n",
    "        \"planner\":   planner_spec,\n",
    "        \"controller\":controller_spec,\n",
    "        \"sensors\":   sensors_spec,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "We define a similar model-based agent and name it as \"human\". Then we instantiate these two agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2_module_spec = {\n",
    "        \"name\":      \"human\",\n",
    "        \"task\":      task_spec,\n",
    "        \"model\":     model_spec,\n",
    "        \"estimator\": estimator_spec,\n",
    "        \"planner\":   planner_spec,\n",
    "        \"controller\":controller_spec,\n",
    "        \"sensors\":   sensors_spec,\n",
    "}\n",
    "\n",
    "agent_specs = [agent1_module_spec, agent2_module_spec] # specs for two agents\n",
    "\n",
    "agents = []\n",
    "for i in range(len(agent_specs)):\n",
    "    agents.append(agent.ModelBasedAgent(agent_specs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = env.FlatEnv(env_spec, agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the agents step by step. In each step, the agent receives observation from the environment and gives action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt, env_info, measurement_groups = e.reset()\n",
    "record = []\n",
    "print(\"Simulation progress:\")\n",
    "for it in progressbar.progressbar(range(1000)):\n",
    "    actions = {}\n",
    "    for agent in agents:\n",
    "        # an action is dictionary which must contain a key \"control\"\n",
    "        actions[agent.name] = agent.action(dt, measurement_groups[agent.name])\n",
    "        #sensor data is grouped by agent\n",
    "    dt, env_info, measurement_groups = e.step(actions, render = (it%50 == 0))\n",
    "    record.append(env_info)\n",
    "\n",
    "ev = evaluator.Evaluator(agent_specs, env_spec)\n",
    "ev.evaluate(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark",
   "language": "python",
   "name": "benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}